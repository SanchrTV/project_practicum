{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "lqkOk9G9teZl"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9dQjjTEmrPk9"
      },
      "outputs": [],
      "source": [
        "class LinearRegression:\n",
        "    def __init__(self, learning_rate=0.01, epochs=1000):\n",
        "        \"\"\"\n",
        "        Инициализация параметров модели.\n",
        "        :param learning_rate: Скорость обучения градиентного спуска.\n",
        "        :param epochs: Количество итераций обучения.\n",
        "        \"\"\"\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Обучение модели с использованием градиентного спуска.\n",
        "        :param X: Матрица признаков (numpy.ndarray).\n",
        "        :param y: Вектор целевых значений (numpy.ndarray).\n",
        "        \"\"\"\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        # Инициализация весов и смещения\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        # Градиентный спуск\n",
        "        for _ in range(self.epochs):\n",
        "            # Предсказания модели\n",
        "            y_pred = np.dot(X, self.weights) + self.bias\n",
        "\n",
        "            # Вычисление градиентов\n",
        "            dw = (1 / n_samples) * np.dot(X.T, (y_pred - y))\n",
        "            db = (1 / n_samples) * np.sum(y_pred - y)\n",
        "\n",
        "            # Обновление параметров\n",
        "            self.weights -= self.learning_rate * dw\n",
        "            self.bias -= self.learning_rate * db\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Предсказание значений для заданных данных.\n",
        "        :param X: Матрица признаков (numpy.ndarray).\n",
        "        :return: Предсказанные значения (numpy.ndarray).\n",
        "        \"\"\"\n",
        "        return np.dot(X, self.weights) + self.bias\n",
        "\n",
        "    def evaluate(self, X, y):\n",
        "        \"\"\"\n",
        "        Оценка модели по метрикам MSE и R^2.\n",
        "        :param X: Матрица признаков (numpy.ndarray).\n",
        "        :param y: Вектор истинных значений (numpy.ndarray).\n",
        "        :return: Словарь с метриками.\n",
        "        \"\"\"\n",
        "        y_pred = self.predict(X)\n",
        "\n",
        "        # Среднеквадратичная ошибка (MSE)\n",
        "        mse = np.mean((y - y_pred) ** 2)\n",
        "\n",
        "        # Коэффициент детерминации (R^2)\n",
        "        total_variance = np.sum((y - np.mean(y)) ** 2)\n",
        "        explained_variance = np.sum((y_pred - np.mean(y)) ** 2)\n",
        "        r2 = explained_variance / total_variance\n",
        "\n",
        "        return {\"MSE\": mse, \"R^2\": r2}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression:\n",
        "    def __init__(self, learning_rate=0.01, epochs=1000):\n",
        "        \"\"\"\n",
        "        Инициализация параметров модели.\n",
        "        :param learning_rate: Скорость обучения градиентного спуска.\n",
        "        :param epochs: Количество итераций обучения.\n",
        "        \"\"\"\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        \"\"\"\n",
        "        Сигмоидная функция активации.\n",
        "        :param z: Линейная комбинация весов и признаков.\n",
        "        :return: Результат применения сигмоидной функции.\n",
        "        \"\"\"\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Обучение модели с использованием градиентного спуска.\n",
        "        :param X: Матрица признаков (numpy.ndarray).\n",
        "        :param y: Вектор целевых значений (numpy.ndarray).\n",
        "        \"\"\"\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        # Инициализация весов и смещения\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        # Градиентный спуск\n",
        "        for _ in range(self.epochs):\n",
        "            # Линейная комбинация весов и признаков\n",
        "            linear_model = np.dot(X, self.weights) + self.bias\n",
        "\n",
        "            # Применение сигмоидной функции\n",
        "            y_pred = self.sigmoid(linear_model)\n",
        "\n",
        "            # Вычисление градиентов\n",
        "            dw = (1 / n_samples) * np.dot(X.T, (y_pred - y))\n",
        "            db = (1 / n_samples) * np.sum(y_pred - y)\n",
        "\n",
        "            # Обновление параметров\n",
        "            self.weights -= self.learning_rate * dw\n",
        "            self.bias -= self.learning_rate * db\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"\n",
        "        Вычисление вероятностей классов.\n",
        "        :param X: Матрица признаков (numpy.ndarray).\n",
        "        :return: Вероятности принадлежности к классу 1 (numpy.ndarray).\n",
        "        \"\"\"\n",
        "        linear_model = np.dot(X, self.weights) + self.bias\n",
        "        return self.sigmoid(linear_model)\n",
        "\n",
        "    def predict(self, X, threshold=0.5):\n",
        "        \"\"\"\n",
        "        Предсказание классов на основе вероятности.\n",
        "        :param X: Матрица признаков (numpy.ndarray).\n",
        "        :param threshold: Порог для классификации.\n",
        "        :return: Предсказанные классы (numpy.ndarray).\n",
        "        \"\"\"\n",
        "        probabilities = self.predict_proba(X)\n",
        "        return (probabilities >= threshold).astype(int)\n",
        "\n",
        "    def evaluate(self, X, y):\n",
        "        \"\"\"\n",
        "        Оценка метрик recall, precision и f1.\n",
        "        :param X: Матрица признаков (numpy.ndarray).\n",
        "        :param y: Вектор истинных значений (numpy.ndarray).\n",
        "        :return: Словарь с метриками.\n",
        "        \"\"\"\n",
        "        y_pred = self.predict(X)\n",
        "\n",
        "        # TP, FP, FN\n",
        "        tp = np.sum((y_pred == 1) & (y == 1))\n",
        "        fp = np.sum((y_pred == 1) & (y == 0))\n",
        "        fn = np.sum((y_pred == 0) & (y == 1))\n",
        "\n",
        "        # Recall, Precision\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "\n",
        "        # F1-Score\n",
        "        f1 = (2 * recall * precision) / (recall + precision) if (recall + precision) > 0 else 0\n",
        "\n",
        "        return {\"Recall\": recall, \"Precision\": precision, \"F1\": f1}"
      ],
      "metadata": {
        "id": "X-gOn4-ntPlK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_vEzVRL5tfr-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}